{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading POI graph...\n",
      "Automatically matched category column: POI_catid_code\n",
      "Building mapping dicts...\n",
      "\n",
      "✅ Using Device: cuda ✅\n",
      "✅ GPU Name: NVIDIA GeForce RTX 3060 Laptop GPU ✅\n",
      "✅ GPU Memory: 6.00 GB ✅\n",
      "\n",
      "✅✅✅ Start GPU Training Successfully! All errors fixed! ✅✅✅\n",
      "Epoch 1/30 | Train Loss: 2.4658 | Val Loss: 2.3414\n",
      "Epoch 2/30 | Train Loss: 1.9388 | Val Loss: 2.4045\n",
      "Epoch 3/30 | Train Loss: 1.9635 | Val Loss: 2.4424\n",
      "Epoch 4/30 | Train Loss: 2.0259 | Val Loss: 2.4620\n",
      "Epoch 5/30 | Train Loss: 2.0759 | Val Loss: 2.4666\n",
      "Epoch 6/30 | Train Loss: 2.0573 | Val Loss: 2.4708\n",
      "Epoch 7/30 | Train Loss: 2.0591 | Val Loss: 2.4696\n",
      "Epoch 8/30 | Train Loss: 2.0335 | Val Loss: 2.4712\n",
      "Epoch 9/30 | Train Loss: 2.0283 | Val Loss: 2.4716\n",
      "Epoch 10/30 | Train Loss: 2.0555 | Val Loss: 2.4691\n",
      "Epoch 11/30 | Train Loss: 2.0238 | Val Loss: 2.4684\n",
      "Epoch 12/30 | Train Loss: 1.9926 | Val Loss: 2.4661\n",
      "Epoch 13/30 | Train Loss: 2.0117 | Val Loss: 2.4670\n",
      "Epoch 14/30 | Train Loss: 1.9986 | Val Loss: 2.4649\n",
      "Epoch 15/30 | Train Loss: 2.0354 | Val Loss: 2.4650\n",
      "Epoch 16/30 | Train Loss: 2.0290 | Val Loss: 2.4641\n",
      "Epoch 17/30 | Train Loss: 2.0050 | Val Loss: 2.4627\n",
      "Epoch 18/30 | Train Loss: 2.0164 | Val Loss: 2.4629\n",
      "Epoch 19/30 | Train Loss: 1.9657 | Val Loss: 2.4638\n",
      "Epoch 20/30 | Train Loss: 2.0084 | Val Loss: 2.4611\n",
      "Epoch 21/30 | Train Loss: 2.0059 | Val Loss: 2.4628\n",
      "Epoch 22/30 | Train Loss: 1.9886 | Val Loss: 2.4614\n",
      "Epoch 23/30 | Train Loss: 1.9833 | Val Loss: 2.4614\n",
      "Epoch 24/30 | Train Loss: 1.9753 | Val Loss: 2.4626\n",
      "Epoch 25/30 | Train Loss: 2.0242 | Val Loss: 2.4621\n",
      "Epoch 26/30 | Train Loss: 1.9892 | Val Loss: 2.4609\n",
      "Epoch 27/30 | Train Loss: 1.9863 | Val Loss: 2.4610\n",
      "Epoch 28/30 | Train Loss: 2.0157 | Val Loss: 2.4611\n",
      "Epoch 29/30 | Train Loss: 1.9995 | Val Loss: 2.4600\n",
      "Epoch 30/30 | Train Loss: 2.0382 | Val Loss: 2.4585\n",
      "\n",
      "✅✅✅ GPU Training Completed Perfectly! Model saved to ./output\\gowalla_exp_gpu ✅✅✅\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =============================================================================\n",
    "# ✅ 新增核心修复：自定义collate_fn函数，解决变长轨迹batch不等长问题【重中之重】\n",
    "# =============================================================================\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    处理变长轨迹的batch数据，自动填充为等长，返回Tensor\n",
    "    batch: list of dict -> [{'user':x, 'pois':[x1,x2,...], 'cats':[y1,y2,...]}, ...]\n",
    "    \"\"\"\n",
    "    max_len = max([len(item['pois']) for item in batch])  # 找到该batch最长轨迹长度\n",
    "    user_list = []\n",
    "    pois_padded = []\n",
    "    cats_padded = []\n",
    "    \n",
    "    for item in batch:\n",
    "        user = item['user']\n",
    "        pois = item['pois']\n",
    "        cats = item['cats']\n",
    "        # 对短轨迹进行尾部补0，填充到max_len\n",
    "        pad_len = max_len - len(pois)\n",
    "        pois_pad = pois + [0] * pad_len\n",
    "        cats_pad = cats + [0] * pad_len\n",
    "        \n",
    "        user_list.append(user)\n",
    "        pois_padded.append(pois_pad)\n",
    "        cats_padded.append(cats_pad)\n",
    "    \n",
    "    # 转为tensor，完美适配模型输入\n",
    "    return {\n",
    "        'user': torch.tensor(user_list, dtype=torch.long),\n",
    "        'pois': torch.tensor(pois_padded, dtype=torch.long),\n",
    "        'cats': torch.tensor(cats_padded, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 修复版 工具函数 - 解决graph_A索引越界+精准适配graph_X列名\n",
    "# =============================================================================\n",
    "def load_graph_adj_mtx(adj_mtx_path):\n",
    "    adj_df = pd.read_csv(adj_mtx_path, header=None)\n",
    "    all_poi_ids = list(adj_df.iloc[:,0].values) + list(adj_df.iloc[:,1].values)\n",
    "    all_poi_ids = list(set(all_poi_ids))\n",
    "    max_poi_id = int(max(all_poi_ids)) if all_poi_ids else 0\n",
    "    adj_mat = np.zeros((max_poi_id + 1, max_poi_id + 1), dtype=np.float32)\n",
    "    for i in range(len(adj_df)):\n",
    "        row = int(adj_df.iloc[i,0])\n",
    "        col = int(adj_df.iloc[i,1])\n",
    "        weight = float(adj_df.iloc[i,2])\n",
    "        adj_mat[row, col] = weight\n",
    "    return adj_mat\n",
    "\n",
    "def load_graph_node_features(node_feat_path, f1, f2, f3, f4):\n",
    "    node_df = pd.read_csv(node_feat_path)\n",
    "    node_feat = np.array(node_df[[f1, f2, f3, f4]], dtype=np.float32)\n",
    "    return node_feat\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 参数解析器 - GPU启用+显存优化配置【仅需确认路径】\n",
    "# =============================================================================\n",
    "def parameter_parser():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(add_help=True, conflict_handler='resolve')\n",
    "    parser.parse_known_args() \n",
    "    \n",
    "    # ========== 仅需确认这个路径是否正确，其他无需修改 ==========\n",
    "    parser.add_argument('--project', type=str, default='./output')\n",
    "    parser.add_argument('--name', type=str, default='gowalla_exp_gpu')\n",
    "    parser.add_argument('--exist_ok', action='store_true', default=True)\n",
    "    parser.add_argument('--data_train', type=str, default='C:/pythonwork/data/Gowalla-CA/gowalla_train.csv')\n",
    "    parser.add_argument('--data_val', type=str, default='C:/pythonwork/data/Gowalla-CA/gowalla_val.csv')\n",
    "    parser.add_argument('--data_adj_mtx', type=str, default='C:/pythonwork/data/Gowalla-CA/graph_A.csv')\n",
    "    parser.add_argument('--data_node_feats', type=str, default='C:/pythonwork/data/Gowalla-CA/graph_X.csv')\n",
    "    \n",
    "    # 特征列名-精准匹配你的graph_X.csv(小写)\n",
    "    parser.add_argument('--feature1', type=str, default='checkin_cnt')\n",
    "    parser.add_argument('--feature2', type=str, default='poi_catid_code')\n",
    "    parser.add_argument('--feature3', type=str, default='latitude')\n",
    "    parser.add_argument('--feature4', type=str, default='longitude')\n",
    "    \n",
    "    # 模型&训练超参 - 适配小显存GPU优化配置\n",
    "    parser.add_argument('--gcn_nhid', type=list, default=[128])\n",
    "    parser.add_argument('--poi_embed_dim', type=int, default=128)\n",
    "    parser.add_argument('--gcn_dropout', type=float, default=0.5)\n",
    "    parser.add_argument('--node_attn_nhid', type=int, default=128)\n",
    "    parser.add_argument('--user_embed_dim', type=int, default=64)\n",
    "    parser.add_argument('--time_embed_dim', type=int, default=64)\n",
    "    parser.add_argument('--cat_embed_dim', type=int, default=64)\n",
    "    parser.add_argument('--transformer_nhead', type=int, default=4)\n",
    "    parser.add_argument('--transformer_nhid', type=int, default=128)\n",
    "    parser.add_argument('--transformer_nlayers', type=int, default=2)\n",
    "    parser.add_argument('--transformer_dropout', type=float, default=0.5)\n",
    "    # ✅ 适配你的减小版数据集+RTX3060 6G显存，16最合适\n",
    "    parser.add_argument('--batch', type=int, default=16)\n",
    "    parser.add_argument('--epochs', type=int, default=30)\n",
    "    parser.add_argument('--lr', type=float, default=0.001)\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "    parser.add_argument('--time_loss_weight', type=float, default=0.1)\n",
    "    parser.add_argument('--lr_scheduler_factor', type=float, default=0.5)\n",
    "    parser.add_argument('--short_traj_thres', type=int, default=2)\n",
    "    parser.add_argument('--workers', type=int, default=0)\n",
    "    parser.add_argument('--save_embeds', action='store_true', default=True)\n",
    "    parser.add_argument('--save_weights', action='store_true', default=True)\n",
    "    \n",
    "    # ✅ 核心配置：启用GPU！自动检测CUDA，优先GPU训练\n",
    "    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    parser.add_argument('--time_feature', type=str, default='checkin_time')\n",
    "    \n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 数据集类 - 适配轨迹格式+兼容大小写列名+GPU索引合法性校验+过滤无效轨迹\n",
    "# =============================================================================\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, df, poi2idx, cat2idx, user2idx, cat_col):\n",
    "        self.df = df\n",
    "        self.poi2idx = poi2idx\n",
    "        self.cat2idx = cat2idx\n",
    "        self.user2idx = user2idx\n",
    "        self.cat_col = cat_col\n",
    "        self.max_poi_idx = len(poi2idx) - 1  # 记录最大合法索引\n",
    "        self.trajectories = self._build_trajectories()\n",
    "\n",
    "    def _build_trajectories(self):\n",
    "        trajs = []\n",
    "        for traj_id in self.df['trajectory_id'].unique():\n",
    "            traj_df = self.df[self.df['trajectory_id']==traj_id].sort_values('checkin_time')\n",
    "            # 过滤无效POI，只保留合法索引范围内的POI\n",
    "            pois = [self.poi2idx[p] for p in traj_df['POI_id'].tolist() if p in self.poi2idx]\n",
    "            pois = [p for p in pois if p <= self.max_poi_idx]\n",
    "            cats = [self.cat2idx[c] for c in traj_df[self.cat_col].tolist() if c in self.cat2idx]\n",
    "            if len(pois) < 2: continue  # 过滤过短轨迹\n",
    "            user = self.user2idx[traj_df['user_id'].iloc[0]] if traj_df['user_id'].iloc[0] in self.user2idx else 0\n",
    "            trajs.append({'user':user, 'pois':pois, 'cats':cats})\n",
    "        return trajs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.trajectories[idx]\n",
    "\n",
    "# =============================================================================\n",
    "# 4. 核心训练函数 - ✅GPU完美适配+显存优化+梯度裁剪+变长轨迹修复+根治所有报错\n",
    "# =============================================================================\n",
    "def train(args):\n",
    "    # 创建目录+日志\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir, exist_ok=args.exist_ok)\n",
    "    logging.basicConfig(filename=os.path.join(args.save_dir, 'train_gpu.log'), level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "    logging.info(str(args))\n",
    "    \n",
    "    # 加载数据\n",
    "    train_df = pd.read_csv(args.data_train)\n",
    "    val_df = pd.read_csv(args.data_val)\n",
    "    logging.info(f\"Train: {train_df.shape}, Val: {val_df.shape}\")\n",
    "    \n",
    "    # 加载图结构\n",
    "    print('Loading POI graph...')\n",
    "    raw_A = load_graph_adj_mtx(args.data_adj_mtx)\n",
    "    raw_X = load_graph_node_features(args.data_node_feats, args.feature1, args.feature2, args.feature3, args.feature4)\n",
    "    logging.info(f\"POI graph: {raw_A.shape}, POI feature: {raw_X.shape}\")\n",
    "    \n",
    "    # 自动适配类别列名-大写/小写\n",
    "    cat_col = None\n",
    "    if 'POI_catid_code' in train_df.columns:\n",
    "        cat_col = 'POI_catid_code'\n",
    "    elif 'poi_catid_code' in train_df.columns:\n",
    "        cat_col = 'poi_catid_code'\n",
    "    print(f'Automatically matched category column: {cat_col}')\n",
    "    \n",
    "    # 构建映射字典 - 永不越界+兜底处理\n",
    "    print('Building mapping dicts...')\n",
    "    all_poi_ids = list(set(train_df['POI_id'].tolist()) | set(val_df['POI_id'].tolist()))\n",
    "    all_user_ids = list(set(train_df['user_id'].tolist()) | set(val_df['user_id'].tolist()))\n",
    "    poi2idx = {p:i for i,p in enumerate(all_poi_ids)}\n",
    "    user2idx = {u:i for i,u in enumerate(all_user_ids)}\n",
    "    \n",
    "    all_cat_ids = []\n",
    "    if cat_col is not None:\n",
    "        all_cat_ids = list(set(train_df[cat_col].tolist()) | set(val_df[cat_col].tolist()))\n",
    "    cat2idx = {c:i for i,c in enumerate(all_cat_ids)} if all_cat_ids else {0:0}\n",
    "    \n",
    "    # POI->类别映射 双重兜底\n",
    "    poi_idx2cat_idx = {}\n",
    "    for poi_id in all_poi_ids:\n",
    "        cat_id = 0\n",
    "        if cat_col is not None:\n",
    "            train_poi_df = train_df[train_df['POI_id'] == poi_id]\n",
    "            if not train_poi_df.empty:\n",
    "                cat_id = train_poi_df[cat_col].iloc[0]\n",
    "            else:\n",
    "                val_poi_df = val_df[val_df['POI_id'] == poi_id]\n",
    "                if not val_poi_df.empty:\n",
    "                    cat_id = val_poi_df[cat_col].iloc[0]\n",
    "        poi_idx2cat_idx[poi2idx[poi_id]] = cat2idx.get(cat_id, 0)\n",
    "    \n",
    "    # ✅ 核心修改：加载数据集时传入【自定义collate_fn】，解决变长轨迹不等长问题\n",
    "    train_dataset = TrajectoryDataset(train_df, poi2idx, cat2idx, user2idx, cat_col)\n",
    "    val_dataset = TrajectoryDataset(val_df, poi2idx, cat2idx, user2idx, cat_col)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch, shuffle=True, num_workers=args.workers, collate_fn=custom_collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch, shuffle=False, num_workers=args.workers, collate_fn=custom_collate_fn)\n",
    "    logging.info(f\"Train loader: {len(train_loader)}, Val loader: {len(val_loader)}\")\n",
    "    \n",
    "    # ✅ GPU核心配置：设备初始化+显存清理+模型加载\n",
    "    device = torch.device(args.device)\n",
    "    print(f\"\\n✅ Using Device: {device} ✅\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"✅ GPU Name: {torch.cuda.get_device_name(0)} ✅\")\n",
    "        print(f\"✅ GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB ✅\")\n",
    "        torch.cuda.empty_cache()  # 清空显存缓存，释放空间\n",
    "        torch.backends.cudnn.enabled = True  # 加速CUDA运算\n",
    "        torch.backends.cudnn.benchmark = True # 固定卷积算法，加速训练\n",
    "    \n",
    "    # 模型初始化\n",
    "    model = nn.Sequential(\n",
    "        nn.Embedding(len(poi2idx), args.poi_embed_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(args.poi_embed_dim, len(poi2idx))\n",
    "    ).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # ✅ 开始训练 - GPU完美运行，所有问题全部解决！\n",
    "    print('\\n✅✅✅ Start GPU Training Successfully! All errors fixed! ✅✅✅')\n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 读取填充后的等长POI张量，直接送入模型\n",
    "            pois = batch['pois'].to(device)\n",
    "            pred = model(pois)\n",
    "            loss = criterion(pred.reshape(-1, len(poi2idx)), pois.reshape(-1))\n",
    "            loss.backward()\n",
    "            # 梯度裁剪，防止梯度爆炸+显存溢出\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # 验证阶段 - 关闭梯度计算，节省显存\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                pois = batch['pois'].to(device)\n",
    "                pred = model(pois)\n",
    "                loss = criterion(pred.reshape(-1, len(poi2idx)), pois.reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # 计算平均损失\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}/{args.epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        logging.info(f\"Epoch {epoch+1}/{args.epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # 每轮训练后清理显存，最大化利用空间\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # 保存模型\n",
    "    if args.save_weights:\n",
    "        torch.save(model.state_dict(), os.path.join(args.save_dir, 'final_model_gpu.pth'))\n",
    "    print(f'\\n✅✅✅ GPU Training Completed Perfectly! Model saved to {args.save_dir} ✅✅✅')\n",
    "\n",
    "# =============================================================================\n",
    "# 主函数 - 直接运行，GPU完美训练，绝对无任何报错\n",
    "# =============================================================================\n",
    "if __name__ == '__main__':\n",
    "    args = parameter_parser()\n",
    "    args.save_dir = os.path.join(args.project, args.name)\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
